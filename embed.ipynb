{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing the necessary libraries\n",
    "%pip install cassio datasets langchain openai tiktoken flask python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra.query import SimpleStatement\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the different tokens\n",
    "load_dotenv()\n",
    "\n",
    "ASTRA_DB_SECURE_BUNDLE_PATH = \"D:\\\\Users\\\\Julien\\\\Documents\\\\developpement\\\\python\\\\embedding-knowledge\\\\secure-connect-vector-database.zip\"\n",
    "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:QMnMDNSekBwcZCCHRmaeqZFI:b2e2fa8e9ca207fcb4e6c35cbbf0be3975c208eb8d20dbfc45259a61bbd25e36\"\n",
    "ASTRA_DB_CLIENT_ID = \"QMnMDNSekBwcZCCHRmaeqZFI\"\n",
    "ASTRA_DC_CLIENT_SECRET = \"_SPYpZuo2ZY5zaANNScG62eWgUBZBtoeX.+2tkAmuCo,k730O5nAWL1PxhE-GMCFY2APc,T.NBReKAl7sZ_XGl7YZOtRNRe+_PwvKAzjmDRgdA7I0mY0Qgd,GeABI8,_\"\n",
    "ASTRA_DB_KEYSPACE = \"search\"\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Vector Store\n",
    "\n",
    "cloud_config={\n",
    "    'secure_connect_bundle': ASTRA_DB_SECURE_BUNDLE_PATH\n",
    "}\n",
    "auth_provider = PlainTextAuthProvider(ASTRA_DB_CLIENT_ID,ASTRA_DC_CLIENT_SECRET)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "astraSession = cluster.connect()\n",
    "\n",
    "llm = OpenAI(openai_api_key = OPENAI_API_KEY)\n",
    "myEmbedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "MyCassandraVStore = Cassandra(\n",
    "    embedding=myEmbedding,\n",
    "    session=astraSession,\n",
    "    keyspace=ASTRA_DB_KEYSPACE,\n",
    "    table_name=\"embedding_demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting everything from astraDB\n",
    "\n",
    "query = SimpleStatement(\"TRUNCATE {}.{}\".format(ASTRA_DB_KEYSPACE, \"embedding_demo\"))\n",
    "astraSession.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from huggingface\n"
     ]
    }
   ],
   "source": [
    "#Loading the data\n",
    "\n",
    "print(\"Loading data from huggingface\")\n",
    "mydataset = load_dataset(\"Biddls/Onion_news\", split=\"train\")\n",
    "headlines = mydataset[\"text\"][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the Embedding in AstraDB\n",
    "\n",
    "print(\"\\nGenerating Embedding and storing in AstraDB\")\n",
    "MyCassandraVStore.add_texts(headlines)\n",
    "\n",
    "print(\"Insert %i headlines.\\n\" % len(headlines))\n",
    "\n",
    "vectorIndex = VectorStoreIndexWrapper(vectorstore=MyCassandraVStore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the content of the Vector store\n",
    "\n",
    "query = SimpleStatement(\"SELECT * FROM {}.{}\".format(ASTRA_DB_KEYSPACE, \"embedding_demo\"))\n",
    "rows = astraSession.execute(query)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Question loop on the embedded llm\n",
    "\n",
    "while True:\n",
    "    query_text = input(\"\\nEnter a question (or type 'quit' to exit):\")\n",
    "\n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    print(\"QUESTION: \\\"%s\\\"\\n\" % query_text)\n",
    "\n",
    "    # Answer without embeddings\n",
    "    answer_without_embeddings = llm.generate([query_text])\n",
    "    print(\"ANSWER WITHOUT EMBEDDINGS: \\\"%s\\\"\\n\" % answer_without_embeddings)\n",
    "\n",
    "    # Answer with embeddings\n",
    "    answer_with_embeddings  = vectorIndex.query(query_text, llm=llm).strip()\n",
    "    print(\"ANSWER WITH EMBEDDINGS: \\\"%s\\\"\\n\" % answer_with_embeddings)\n",
    "\n",
    "    #Mots relevant documents\n",
    "    print(\"DOCUMENTS BY RELEVANCE:\")\n",
    "    for doc, score in MyCassandraVStore.similarity_search_with_score(query_text, k=4):\n",
    "        print(\"  %0.4f \\\"%s ...\\\"\" % (score, doc.page_content[:60]))\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://192.168.0.10:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "#expose a webservice instead\n",
    "\n",
    "import threading\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/ask', methods=['POST'])\n",
    "def ask():\n",
    "    query_text = request.json['question']\n",
    "\n",
    "    # Answer without embeddings\n",
    "    answer_without_embeddings = llm.generate([query_text])\n",
    "    answer_without_embeddings = answer_without_embeddings.generations[0][0].text.strip()\n",
    "\n",
    "    # Answer with embeddings\n",
    "    answer_with_embeddings  = vectorIndex.query(query_text, llm=llm).strip()\n",
    "\n",
    "    # Documents by relevance\n",
    "    documents_by_relevance = [\n",
    "        {\"score\": score, \"content\": doc.page_content[:60]}\n",
    "        for doc, score in MyCassandraVStore.similarity_search_with_score(query_text, k=4)\n",
    "    ]\n",
    "\n",
    "    return jsonify({\n",
    "        \"question\": query_text,\n",
    "        \"answer_without_embeddings\": answer_without_embeddings,\n",
    "        \"answer_with_embeddings\": answer_with_embeddings,\n",
    "        \"documents_by_relevance\": documents_by_relevance,\n",
    "    })\n",
    "\n",
    "def run_flask():\n",
    "    app.run(host='192.168.0.10', port=5000)\n",
    "\n",
    "threading.Thread(target=run_flask).start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
